{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys; sys.path.insert(0, os.path.abspath(\"../\"))\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import cv2\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dataset.dataset import SkinLesion_Dataset, SegExamples\n",
    "from pipeline.preprocessing import SkinLesionPreprocessing\n",
    "from pipeline.feature_extraction import FeaturesExtraction\n",
    "\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, accuracy_score, make_scorer, cohen_kappa_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from boruta import BorutaPy\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (15195, 203), y_train: (15195,), X_test: (3796, 203), y_test: (3796,)\n",
      "final class balance [TRAIN]: (array([0, 1], dtype=int64), array([7470, 7725], dtype=int64)) [VAL]: (array([0, 1], dtype=int64), array([1865, 1931], dtype=int64))\n",
      "X_var: (18991, 151)\n",
      "Performing Feature Selection ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sfm: (18991, 132)\n",
      "X_train_var: (15195, 151), y_train: (15195,), X_test_var: (3796, 151), y_test: (3796,)\n",
      "X_train_new: (15195, 132), y_train: (15195,), X_test_new: (3796, 132), y_test: (3796,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df_1 = pd.read_feather(\"../data/binary/train_all_feat.f\")\n",
    "train_df_2 = pd.read_feather(\"../data/binary/train_color_local_feat.f\")\n",
    "val_df_1 = pd.read_feather(\"../data/binary/val_all_features.f\")\n",
    "val_df_2 = pd.read_feather(\"../data/binary/val_color_local_feat.f\")\n",
    "\n",
    "train_df = pd.concat([train_df_2.iloc[:,:60], train_df_1], axis=1)\n",
    "val_df = pd.concat([val_df_2.iloc[:, :60], val_df_1], axis=1)\n",
    "\n",
    "train_shape = train_df.shape\n",
    "val_shape = val_df.shape\n",
    "\n",
    "train_df.replace({'nevus': 1, 'others': 0}, inplace=True)\n",
    "val_df.replace({'nevus': 1, 'others': 0}, inplace=True)\n",
    "\n",
    "df_train = train_df.iloc[:train_shape[0], :].sample(frac=1, random_state=42)\n",
    "df_val = val_df.iloc[:val_shape[0], :].sample(frac=1, random_state=42)\n",
    "# df_val\n",
    "\n",
    "X_train, y_train = df_train.iloc[:, :(train_shape[1]-1)].to_numpy(dtype=np.float32), df_train.iloc[:, (train_shape[1]-1)].to_numpy()\n",
    "X_test, y_test = df_val.iloc[:, :(val_shape[1]-1)].to_numpy(dtype= np.float32), df_val.iloc[:, (val_shape[1]-1)].to_numpy()\n",
    "\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}')\n",
    "print(f'final class balance [TRAIN]: {np.unique(y_train, return_counts=True)}', f'[VAL]: {np.unique(y_test, return_counts=True)}')\n",
    "\n",
    "X_train_f = pd.DataFrame(X_train)\n",
    "X_test_f = pd.DataFrame(X_test)\n",
    "y_train_f = pd.DataFrame(y_train)\n",
    "y_test_f = pd.DataFrame(y_test)\n",
    "frames = [X_train_f, X_test_f]\n",
    "f = [y_train_f, y_test_f]\n",
    "X = pd.concat(frames)\n",
    "y = pd.concat(f)\n",
    "\n",
    "# Feature Selection -- VARIANCE THRESHOLD\n",
    "sel_var = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "X_var= sel_var.fit_transform(X)\n",
    "print(f'X_var: {X_var.shape}')\n",
    "\n",
    "## Feature Selection -- SelectFromModel\n",
    "sel_sfm = SelectFromModel(LinearSVC(C = 0.09, penalty=\"l1\",  dual=False))\n",
    "print(\"Performing Feature Selection ... \")\n",
    "X_sfm = sel_sfm.fit_transform(X, y)\n",
    "print(f'X_sfm: {X_sfm.shape}')\n",
    "\n",
    "# split dataframe X again into train and test -- VARIANCE THRESHOLD\n",
    "X_train_var = pd.DataFrame(X_var).iloc[:len(X_train_f[0])].to_numpy(dtype=np.float32)\n",
    "X_test_var = pd.DataFrame(X_var).iloc[len(X_train_f[0]):].to_numpy(dtype=np.float32)\n",
    "y_train_new = pd.DataFrame(y).iloc[:len(y_train_f[0])].to_numpy(dtype=np.float32)\n",
    "y_test_new = pd.DataFrame(y).iloc[len(y_train_f[0]):].to_numpy(dtype=np.float32)\n",
    "print(f'X_train_var: {X_train_var.shape}, y_train: {y_train.shape}, X_test_var: {X_test_var.shape}, y_test: {y_test.shape}')\n",
    "\n",
    "# split dataframe X again into train and test SFM\n",
    "X_train_new = pd.DataFrame(X_sfm).iloc[:len(X_train_f[0])].to_numpy(dtype=np.float32)\n",
    "X_test_new = pd.DataFrame(X_sfm).iloc[len(X_train_f[0]):].to_numpy(dtype=np.float32)\n",
    "y_train_new = pd.DataFrame(y).iloc[:len(y_train_f[0])].to_numpy(dtype=np.float32)\n",
    "y_test_new = pd.DataFrame(y).iloc[len(y_train_f[0]):].to_numpy(dtype=np.float32)\n",
    "print(f'X_train_new: {X_train_new.shape}, y_train: {y_train.shape}, X_test_new: {X_test_new.shape}, y_test: {y_test.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support Vector Classifier (SVC)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9359 Acc: 0.9359657782165186\n",
      "F1 Score of test data: 0.8508 Acc: 0.850895679662803\n"
     ]
    }
   ],
   "source": [
    "# Without Feature Selection\n",
    "classifier = svm.SVC(C= 10, kernel= 'rbf')\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "C:\\Users\\Lenovo\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9245 Acc: 0.9245804540967424\n",
      "F1 Score of test data: 0.8416 Acc: 0.8416754478398314\n"
     ]
    }
   ],
   "source": [
    "# With Variance Thresholding Feature Selection\n",
    "classifier = svm.SVC(C= 10, kernel= 'rbf')\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train_var, y_train_new)\n",
    "y_train_predicted = pipe.predict(X_train_var)\n",
    "y_test_predicted =  pipe.predict(X_test_var)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train_new,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train_new, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test_new,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test_new, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "C:\\Users\\Lenovo\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9257 Acc: 0.9256992431720961\n",
      "F1 Score of test data: 0.8457 Acc: 0.8458904109589042\n"
     ]
    }
   ],
   "source": [
    "# With Select from model method\n",
    "classifier = svm.SVC(C= 10, kernel= 'rbf')\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train_new, y_train_new)\n",
    "y_train_predicted = pipe.predict(X_train_new)\n",
    "y_test_predicted =  pipe.predict(X_test_new)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train_new,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train_new, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test_new,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test_new, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9923 Acc: 0.9923000987166831\n",
      "F1 Score of test data: 0.8373 Acc: 0.8374604847207587\n"
     ]
    }
   ],
   "source": [
    "# Default xgboost without gridsearch\n",
    "classifier = xgb.XGBClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9895 Acc: 0.989470220467259\n",
      "F1 Score of test data: 0.8239 Acc: 0.8240252897787145\n"
     ]
    }
   ],
   "source": [
    "# With Variance Thresholding Feature Selection\n",
    "classifier = xgb.XGBClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train_var, y_train_new)\n",
    "y_train_predicted = pipe.predict(X_train_var)\n",
    "y_test_predicted =  pipe.predict(X_test_var)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train_new,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train_new, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test_new,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test_new, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9850 Acc: 0.984995064165844\n",
      "F1 Score of test data: 0.8249 Acc: 0.8250790305584826\n"
     ]
    }
   ],
   "source": [
    "# With Select from model method\n",
    "classifier = xgb.XGBClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train_new, y_train_new)\n",
    "y_train_predicted = pipe.predict(X_train_new)\n",
    "y_test_predicted =  pipe.predict(X_test_new)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train_new,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train_new, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test_new,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test_new, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.neighbors.KNeighborsClassifier.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.neighbors.KNeighborsClassifier.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.8807 Acc: 0.8806844356696282\n",
      "F1 Score of test data: 0.8132 Acc: 0.8132244467860906\n"
     ]
    }
   ],
   "source": [
    "# KNN deafult\n",
    "classifier = KNeighborsClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adaboost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.8171 Acc: 0.8171108917407042\n",
      "F1 Score of test data: 0.8084 Acc: 0.8084826132771338\n"
     ]
    }
   ],
   "source": [
    "# Adaboost with the best grid search\n",
    "classifier = AdaBoostClassifier(learning_rate= 0.1, n_estimators=500)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\daal4py\\sklearn\\linear_model\\logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "INFO:root:sklearn.linear_model.LogisticRegression.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.linear_model.LogisticRegression.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.linear_model.LogisticRegression.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.8097 Acc: 0.8097400460677855\n",
      "F1 Score of test data: 0.8094 Acc: 0.809536354056902\n"
     ]
    }
   ],
   "source": [
    "# LR Default\n",
    "classifier = LogisticRegression(C= 3, penalty= 'l2')\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.ensemble.RandomForestClassifier.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 1.0000 Acc: 1.0\n",
      "F1 Score of test data: 0.8303 Acc: 0.8303477344573235\n"
     ]
    }
   ],
   "source": [
    "# RF default\n",
    "classifier = RandomForestClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.ensemble.RandomForestClassifier.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 1.0000 Acc: 1.0\n",
      "F1 Score of test data: 0.8331 Acc: 0.833245521601686\n"
     ]
    }
   ],
   "source": [
    "# RF with grid search result\n",
    "classifier = RandomForestClassifier(max_depth= 50, n_estimators=1000)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.8398 Acc: 0.8398815399802566\n",
      "F1 Score of test data: 0.8102 Acc: 0.8103266596417281\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting default values\n",
    "classifier =GradientBoostingClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [26], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m classifier \u001B[38;5;241m=\u001B[39mGradientBoostingClassifier(learning_rate \u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlog_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, n_estimators \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m200\u001B[39m)\n\u001B[0;32m      4\u001B[0m pipe \u001B[38;5;241m=\u001B[39m Pipeline([(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscaler\u001B[39m\u001B[38;5;124m'\u001B[39m, StandardScaler()),(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassifier\u001B[39m\u001B[38;5;124m'\u001B[39m, classifier)])\n\u001B[1;32m----> 5\u001B[0m pipe\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m      6\u001B[0m y_train_predicted \u001B[38;5;241m=\u001B[39m pipe\u001B[38;5;241m.\u001B[39mpredict(X_train)\n\u001B[0;32m      7\u001B[0m y_test_predicted \u001B[38;5;241m=\u001B[39m  pipe\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[1;32m~\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\sklearn\\pipeline.py:382\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    381\u001B[0m         fit_params_last_step \u001B[38;5;241m=\u001B[39m fit_params_steps[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]]\n\u001B[1;32m--> 382\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator\u001B[38;5;241m.\u001B[39mfit(Xt, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params_last_step)\n\u001B[0;32m    384\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:668\u001B[0m, in \u001B[0;36mBaseGradientBoosting.fit\u001B[1;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[0;32m    665\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resize_state()\n\u001B[0;32m    667\u001B[0m \u001B[38;5;66;03m# fit the boosting stages\u001B[39;00m\n\u001B[1;32m--> 668\u001B[0m n_stages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stages\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_rng\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbegin_at_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmonitor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    679\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001B[39;00m\n\u001B[0;32m    682\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_stages \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[1;32m~\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:745\u001B[0m, in \u001B[0;36mBaseGradientBoosting._fit_stages\u001B[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001B[0m\n\u001B[0;32m    738\u001B[0m     old_oob_score \u001B[38;5;241m=\u001B[39m loss_(\n\u001B[0;32m    739\u001B[0m         y[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[0;32m    740\u001B[0m         raw_predictions[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[0;32m    741\u001B[0m         sample_weight[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[0;32m    742\u001B[0m     )\n\u001B[0;32m    744\u001B[0m \u001B[38;5;66;03m# fit next stage of trees\u001B[39;00m\n\u001B[1;32m--> 745\u001B[0m raw_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stage\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    748\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    749\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    750\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    751\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    752\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    753\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_csc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    754\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_csr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    755\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    757\u001B[0m \u001B[38;5;66;03m# track deviance (= loss)\u001B[39;00m\n\u001B[0;32m    758\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_oob:\n",
      "File \u001B[1;32m~\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:247\u001B[0m, in \u001B[0;36mBaseGradientBoosting._fit_stage\u001B[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001B[0m\n\u001B[0;32m    244\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m sample_weight \u001B[38;5;241m*\u001B[39m sample_mask\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[0;32m    246\u001B[0m X \u001B[38;5;241m=\u001B[39m X_csr \u001B[38;5;28;01mif\u001B[39;00m X_csr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m X\n\u001B[1;32m--> 247\u001B[0m \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresidual\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# update tree leaves\u001B[39;00m\n\u001B[0;32m    250\u001B[0m loss\u001B[38;5;241m.\u001B[39mupdate_terminal_regions(\n\u001B[0;32m    251\u001B[0m     tree\u001B[38;5;241m.\u001B[39mtree_,\n\u001B[0;32m    252\u001B[0m     X,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    259\u001B[0m     k\u001B[38;5;241m=\u001B[39mk,\n\u001B[0;32m    260\u001B[0m )\n",
      "File \u001B[1;32m~\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\sklearn\\tree\\_classes.py:1342\u001B[0m, in \u001B[0;36mDecisionTreeRegressor.fit\u001B[1;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[0;32m   1313\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m   1314\u001B[0m     \u001B[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001B[39;00m\n\u001B[0;32m   1315\u001B[0m \n\u001B[0;32m   1316\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1339\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[0;32m   1340\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1342\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1343\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1344\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1345\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1346\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1347\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1348\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001B[0m, in \u001B[0;36mBaseDecisionTree.fit\u001B[1;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[0;32m    447\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    448\u001B[0m     builder \u001B[38;5;241m=\u001B[39m BestFirstTreeBuilder(\n\u001B[0;32m    449\u001B[0m         splitter,\n\u001B[0;32m    450\u001B[0m         min_samples_split,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    455\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_impurity_decrease,\n\u001B[0;32m    456\u001B[0m     )\n\u001B[1;32m--> 458\u001B[0m \u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    461\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Gradient boosting grid search values\n",
    "\n",
    "classifier =GradientBoostingClassifier(learning_rate =0.1, loss = 'log_loss', n_estimators = 200)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
