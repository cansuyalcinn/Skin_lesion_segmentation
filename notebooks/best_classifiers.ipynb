{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys; sys.path.insert(0, os.path.abspath(\"../\"))\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import cv2\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dataset.dataset import SkinLesion_Dataset, SegExamples\n",
    "from pipeline.preprocessing import SkinLesionPreprocessing\n",
    "from pipeline.feature_extraction import FeaturesExtraction\n",
    "\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, accuracy_score, make_scorer, cohen_kappa_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from boruta import BorutaPy\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (15195, 203), y_train: (15195,), X_test: (3796, 203), y_test: (3796,)\n",
      "final class balance [TRAIN]: (array([0, 1], dtype=int64), array([7470, 7725], dtype=int64)) [VAL]: (array([0, 1], dtype=int64), array([1865, 1931], dtype=int64))\n",
      "X_var: (18991, 151)\n",
      "Performing Feature Selection ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sfm: (18991, 132)\n",
      "X_train_var: (15195, 151), y_train: (15195,), X_test_var: (3796, 151), y_test: (3796,)\n",
      "X_train_new: (15195, 132), y_train: (15195,), X_test_new: (3796, 132), y_test: (3796,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df_1 = pd.read_feather(\"../data/binary/train_all_feat.f\")\n",
    "train_df_2 = pd.read_feather(\"../data/binary/train_color_local_feat.f\")\n",
    "val_df_1 = pd.read_feather(\"../data/binary/val_all_features.f\")\n",
    "val_df_2 = pd.read_feather(\"../data/binary/val_color_local_feat.f\")\n",
    "\n",
    "train_df = pd.concat([train_df_2.iloc[:,:60], train_df_1], axis=1)\n",
    "val_df = pd.concat([val_df_2.iloc[:, :60], val_df_1], axis=1)\n",
    "\n",
    "train_shape = train_df.shape\n",
    "val_shape = val_df.shape\n",
    "\n",
    "train_df.replace({'nevus': 1, 'others': 0}, inplace=True)\n",
    "val_df.replace({'nevus': 1, 'others': 0}, inplace=True)\n",
    "\n",
    "df_train = train_df.iloc[:train_shape[0], :].sample(frac=1, random_state=42)\n",
    "df_val = val_df.iloc[:val_shape[0], :].sample(frac=1, random_state=42)\n",
    "# df_val\n",
    "\n",
    "X_train, y_train = df_train.iloc[:, :(train_shape[1]-1)].to_numpy(dtype=np.float32), df_train.iloc[:, (train_shape[1]-1)].to_numpy()\n",
    "X_test, y_test = df_val.iloc[:, :(val_shape[1]-1)].to_numpy(dtype= np.float32), df_val.iloc[:, (val_shape[1]-1)].to_numpy()\n",
    "\n",
    "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}')\n",
    "print(f'final class balance [TRAIN]: {np.unique(y_train, return_counts=True)}', f'[VAL]: {np.unique(y_test, return_counts=True)}')\n",
    "\n",
    "X_train_f = pd.DataFrame(X_train)\n",
    "X_test_f = pd.DataFrame(X_test)\n",
    "y_train_f = pd.DataFrame(y_train)\n",
    "y_test_f = pd.DataFrame(y_test)\n",
    "frames = [X_train_f, X_test_f]\n",
    "f = [y_train_f, y_test_f]\n",
    "X = pd.concat(frames)\n",
    "y = pd.concat(f)\n",
    "\n",
    "# Feature Selection -- VARIANCE THRESHOLD\n",
    "sel_var = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "X_var= sel_var.fit_transform(X)\n",
    "print(f'X_var: {X_var.shape}')\n",
    "\n",
    "## Feature Selection -- SelectFromModel\n",
    "sel_sfm = SelectFromModel(LinearSVC(C = 0.09, penalty=\"l1\",  dual=False))\n",
    "print(\"Performing Feature Selection ... \")\n",
    "X_sfm = sel_sfm.fit_transform(X, y)\n",
    "print(f'X_sfm: {X_sfm.shape}')\n",
    "\n",
    "# split dataframe X again into train and test -- VARIANCE THRESHOLD\n",
    "X_train_var = pd.DataFrame(X_var).iloc[:len(X_train_f[0])].to_numpy(dtype=np.float32)\n",
    "X_test_var = pd.DataFrame(X_var).iloc[len(X_train_f[0]):].to_numpy(dtype=np.float32)\n",
    "y_train_new = pd.DataFrame(y).iloc[:len(y_train_f[0])].to_numpy(dtype=np.float32)\n",
    "y_test_new = pd.DataFrame(y).iloc[len(y_train_f[0]):].to_numpy(dtype=np.float32)\n",
    "print(f'X_train_var: {X_train_var.shape}, y_train: {y_train.shape}, X_test_var: {X_test_var.shape}, y_test: {y_test.shape}')\n",
    "\n",
    "# split dataframe X again into train and test SFM\n",
    "X_train_new = pd.DataFrame(X_sfm).iloc[:len(X_train_f[0])].to_numpy(dtype=np.float32)\n",
    "X_test_new = pd.DataFrame(X_sfm).iloc[len(X_train_f[0]):].to_numpy(dtype=np.float32)\n",
    "y_train_new = pd.DataFrame(y).iloc[:len(y_train_f[0])].to_numpy(dtype=np.float32)\n",
    "y_test_new = pd.DataFrame(y).iloc[len(y_train_f[0]):].to_numpy(dtype=np.float32)\n",
    "print(f'X_train_new: {X_train_new.shape}, y_train: {y_train.shape}, X_test_new: {X_test_new.shape}, y_test: {y_test.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support Vector Classifier (SVC)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9359 Acc: 0.9359657782165186\n",
      "F1 Score of test data: 0.8508 Acc: 0.850895679662803\n"
     ]
    }
   ],
   "source": [
    "# Without Feature Selection\n",
    "classifier = svm.SVC(C= 10, kernel= 'rbf')\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "C:\\Users\\Lenovo\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9245 Acc: 0.9245804540967424\n",
      "F1 Score of test data: 0.8416 Acc: 0.8416754478398314\n"
     ]
    }
   ],
   "source": [
    "# With Variance Thresholding Feature Selection\n",
    "classifier = svm.SVC(C= 10, kernel= 'rbf')\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train_var, y_train_new)\n",
    "y_train_predicted = pipe.predict(X_train_var)\n",
    "y_test_predicted =  pipe.predict(X_test_var)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train_new,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train_new, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test_new,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test_new, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "C:\\Users\\Lenovo\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\onedal\\datatypes\\validation.py:127: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = _column_or_1d(y, warn=True)\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9257 Acc: 0.9256992431720961\n",
      "F1 Score of test data: 0.8457 Acc: 0.8458904109589042\n"
     ]
    }
   ],
   "source": [
    "# With Select from model method\n",
    "classifier = svm.SVC(C= 10, kernel= 'rbf')\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train_new, y_train_new)\n",
    "y_train_predicted = pipe.predict(X_train_new)\n",
    "y_test_predicted =  pipe.predict(X_test_new)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train_new,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train_new, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test_new,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test_new, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9923 Acc: 0.9923000987166831\n",
      "F1 Score of test data: 0.8373 Acc: 0.8374604847207587\n"
     ]
    }
   ],
   "source": [
    "# Default xgboost without gridsearch\n",
    "classifier = xgb.XGBClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9895 Acc: 0.989470220467259\n",
      "F1 Score of test data: 0.8239 Acc: 0.8240252897787145\n"
     ]
    }
   ],
   "source": [
    "# With Variance Thresholding Feature Selection\n",
    "classifier = xgb.XGBClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train_var, y_train_new)\n",
    "y_train_predicted = pipe.predict(X_train_var)\n",
    "y_test_predicted =  pipe.predict(X_test_var)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train_new,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train_new, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test_new,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test_new, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.9850 Acc: 0.984995064165844\n",
      "F1 Score of test data: 0.8249 Acc: 0.8250790305584826\n"
     ]
    }
   ],
   "source": [
    "# With Select from model method\n",
    "classifier = xgb.XGBClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train_new, y_train_new)\n",
    "y_train_predicted = pipe.predict(X_train_new)\n",
    "y_test_predicted =  pipe.predict(X_test_new)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train_new,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train_new, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test_new,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test_new, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.neighbors.KNeighborsClassifier.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.neighbors.KNeighborsClassifier.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.8807 Acc: 0.8806844356696282\n",
      "F1 Score of test data: 0.8132 Acc: 0.8132244467860906\n"
     ]
    }
   ],
   "source": [
    "# KNN deafult\n",
    "classifier = KNeighborsClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adaboost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.8171 Acc: 0.8171108917407042\n",
      "F1 Score of test data: 0.8084 Acc: 0.8084826132771338\n"
     ]
    }
   ],
   "source": [
    "# Adaboost with the best grid search\n",
    "classifier = AdaBoostClassifier(learning_rate= 0.1, n_estimators=500)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.virtualenvs\\Skin_lesion_segmentation\\lib\\site-packages\\daal4py\\sklearn\\linear_model\\logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "INFO:root:sklearn.linear_model.LogisticRegression.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.linear_model.LogisticRegression.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.linear_model.LogisticRegression.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.8097 Acc: 0.8097400460677855\n",
      "F1 Score of test data: 0.8094 Acc: 0.809536354056902\n"
     ]
    }
   ],
   "source": [
    "# LR Default\n",
    "classifier = LogisticRegression(C= 3, penalty= 'l2')\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.ensemble.RandomForestClassifier.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 1.0000 Acc: 1.0\n",
      "F1 Score of test data: 0.8303 Acc: 0.8303477344573235\n"
     ]
    }
   ],
   "source": [
    "# RF default\n",
    "classifier = RandomForestClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.ensemble.RandomForestClassifier.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 1.0000 Acc: 1.0\n",
      "F1 Score of test data: 0.8331 Acc: 0.833245521601686\n"
     ]
    }
   ],
   "source": [
    "# RF with grid search result\n",
    "classifier = RandomForestClassifier(max_depth= 50, n_estimators=1000)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.8398 Acc: 0.8398815399802566\n",
      "F1 Score of test data: 0.8102 Acc: 0.8103266596417281\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting default values\n",
    "classifier =GradientBoostingClassifier()\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of train data: 0.8611 Acc: 0.8611385324119776\n",
      "F1 Score of test data: 0.8176 Acc: 0.8177028451001054\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting grid search values\n",
    "\n",
    "classifier =GradientBoostingClassifier(learning_rate =0.1, loss = 'log_loss', n_estimators = 200)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier', classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_train_predicted = pipe.predict(X_train)\n",
    "y_test_predicted =  pipe.predict(X_test)\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensemble of the models 1: Max Voting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The selected models are SVC, Random forest and Xgboost classifiers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.723168762478601\n",
      "F1 Score of train data: 0.9930 Acc: 0.9929582099374794\n",
      "F1 Score of test data: 0.8342 Acc: 0.8342992623814541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model_1 = svm.SVC(C= 10, kernel= 'rbf', probability=True)\n",
    "model_2 = RandomForestClassifier(max_depth= 50, n_estimators=1000)\n",
    "model_3 = xgb.XGBClassifier()\n",
    "final_model = VotingClassifier(estimators=[('svc', model_1), ('rf', model_2), ('xgb', model_3)], voting='hard')\n",
    "final_model.fit(X_train, y_train)\n",
    "y_train_predicted = final_model.predict(X_train)\n",
    "y_test_predicted = final_model.predict(X_test)\n",
    "\n",
    "# printing log loss between actual and predicted value\n",
    "print(log_loss(y_test, y_test_predicted))\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict_proba: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.decision_function: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict_proba: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict_proba: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.decision_function: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict_proba: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.777760927592414\n",
      "F1 Score of train data: 0.9875 Acc: 0.98749588680487\n",
      "F1 Score of test data: 0.8327 Acc: 0.8327186512118019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model_1 = svm.SVC(C= 10, kernel= 'rbf', probability=True)\n",
    "model_2 = RandomForestClassifier(max_depth= 50, n_estimators=1000)\n",
    "model_3 = xgb.XGBClassifier()\n",
    "final_model = VotingClassifier(estimators=[('svc', model_1), ('rf', model_2), ('xgb', model_3)], voting='soft')\n",
    "final_model.fit(X_train, y_train)\n",
    "y_train_predicted = final_model.predict(X_train)\n",
    "y_test_predicted = final_model.predict(X_test)\n",
    "\n",
    "# printing log loss between actual and predicted value\n",
    "print(log_loss(y_test, y_test_predicted))\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.677675326657442\n",
      "F1 Score of train data: 0.9930 Acc: 0.9929582099374794\n",
      "F1 Score of test data: 0.8355 Acc: 0.8356164383561644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model_1 = svm.SVC(C= 10, kernel= 'rbf', probability=True)\n",
    "model_2 = RandomForestClassifier(max_depth= 50, n_estimators=1000)\n",
    "model_3 = xgb.XGBClassifier()\n",
    "final_model = VotingClassifier(estimators=[('svc', model_1), ('rf', model_2), ('xgb', model_3)], voting='hard', weights=[0.85,0.83,0.83])\n",
    "final_model.fit(X_train, y_train)\n",
    "y_train_predicted = final_model.predict(X_train)\n",
    "y_test_predicted = final_model.predict(X_test)\n",
    "\n",
    "# printing log loss between actual and predicted value\n",
    "print(log_loss(y_test, y_test_predicted))\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.fit: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict_proba: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.decision_function: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict_proba: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.predict_proba: running accelerated version on CPU\n",
      "INFO:root:sklearn.svm.SVC.decision_function: running accelerated version on CPU\n",
      "INFO:root:sklearn.ensemble.RandomForestClassifier.predict_proba: running accelerated version on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.814156476689342\n",
      "F1 Score of train data: 0.9866 Acc: 0.9865745310957552\n",
      "F1 Score of test data: 0.8316 Acc: 0.8316649104320337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model_1 = svm.SVC(C= 10, kernel= 'rbf', probability=True)\n",
    "model_2 = RandomForestClassifier(max_depth= 50, n_estimators=1000)\n",
    "model_3 = xgb.XGBClassifier()\n",
    "final_model = VotingClassifier(estimators=[('svc', model_1), ('rf', model_2), ('xgb', model_3)], voting='soft', weights=[0.85,0.83,0.83])\n",
    "final_model.fit(X_train, y_train)\n",
    "y_train_predicted = final_model.predict(X_train)\n",
    "y_test_predicted = final_model.predict(X_test)\n",
    "\n",
    "# printing log loss between actual and predicted value\n",
    "print(log_loss(y_test, y_test_predicted))\n",
    "print('F1 Score of train data: %0.4f' %f1_score(y_train,y_train_predicted,average='macro'), f'Acc: {accuracy_score(y_train, y_train_predicted)}')\n",
    "print('F1 Score of test data: %0.4f' %f1_score(y_test,y_test_predicted,average='macro'), f'Acc: {accuracy_score(y_test, y_test_predicted)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
