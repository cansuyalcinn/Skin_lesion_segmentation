{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def crop_img(img, threshold=100):\n",
    "    '''\n",
    "    Crop the image to get the region of interest. Remove the vignette frame.\n",
    "    Analyze the value of the pixels in the diagonal of the image, from 0,0 to h,w and\n",
    "    take the points where this value crosses the threshold by the first time and for last.\n",
    "    Args:\n",
    "    - img (numpy ndarray): Image to crop.\n",
    "    - threshold (int): Value to split the diagonal into image and frame.\n",
    "    Return:\n",
    "    - The coordinates of the rectangle and the cropped image.\n",
    "    '''\n",
    "    # Get the image dimensions\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Get the coordinates of the pixels in the diagonal\n",
    "    if h != 1024:\n",
    "        y_coords = ([i for i in range(0, h, 3)], [i for i in range(h - 3, -1, -3)])\n",
    "    y_coords = ([i for i in range(0, h, 4)], [i for i in range(h - 4, -1, -4)])\n",
    "    x_coords = ([i for i in range(0, w, 4)], [i for i in range(0, w, 4)])\n",
    "\n",
    "    # Get the mean value of the pixels in the diagonal, form 0,0 to h,w\n",
    "    # and from h,0 to 0,w\n",
    "    coordinates = {'y1_1': 0, 'x1_1': 0, 'y2_1': h, 'x2_1': w, 'y1_2': h, 'x1_2': 0, 'y2_2': 0, 'x2_2': w}\n",
    "    for i in range(2):\n",
    "        d = []\n",
    "        y1_aux, x1_aux = 0, 0\n",
    "        y2_aux, x2_aux = h, w\n",
    "        for y, x in zip(y_coords[i], x_coords[i]):\n",
    "            d.append(np.mean(img[y, x, :]))\n",
    "\n",
    "        # Get the location of the first point where the threshold is crossed\n",
    "        for idx, value in enumerate(d):\n",
    "            if value >= threshold:\n",
    "                coordinates['y1_' + str(i + 1)] = y_coords[i][idx]\n",
    "                coordinates['x1_' + str(i + 1)] = x_coords[i][idx]\n",
    "                break\n",
    "\n",
    "        # Get the location of the last point where the threshold is crossed\n",
    "        for idx, value in enumerate(reversed(d)):\n",
    "            if value >= threshold:\n",
    "                coordinates['y2_' + str(i + 1)] = y_coords[i][-idx if idx != 0 else -1]\n",
    "                coordinates['x2_' + str(i + 1)] = x_coords[i][-idx if idx != 0 else -1]\n",
    "                break\n",
    "\n",
    "    # Set the coordinates to crop the image\n",
    "\n",
    "    # # modified\n",
    "    # # y1 = min(coordinates['y1_1'], coordinates['y1_2'])\n",
    "    # # y2 = max(coordinates['y2_1'], coordinates['y2_2'])\n",
    "\n",
    "    # # original\n",
    "    # y1 = max(coordinates['y1_1'], coordinates['y2_2'])\n",
    "    # y2 = min(coordinates['y2_1'], coordinates['y1_2'])\n",
    "\n",
    "    # # original\n",
    "    # # x1 = max(coordinates['x1_1'], coordinates['x1_2'])\n",
    "    # # x2 = min(coordinates['x2_1'], coordinates['x2_2'])\n",
    "\n",
    "    # # modified\n",
    "    # x1 = max(coordinates['x1_1'], coordinates['x2_2'])\n",
    "    # x2 = min(coordinates['x2_1'], coordinates['x1_2'])\n",
    "\n",
    "    # Set the coordinates to crop the image\n",
    "    y1 = max(coordinates['y1_1'], coordinates['y2_2'])\n",
    "    y2 = min(coordinates['y2_1'], coordinates['y1_2'])\n",
    "    x1 = max(coordinates['x1_1'], coordinates['x1_2'])\n",
    "    x2 = min(coordinates['x2_1'], coordinates['x2_2'])\n",
    "\n",
    "    return img[y1:y2, x1:x2, :], y1, y2, x1, x2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.dataset import SkinLesion_Dataset, SegExamples\n",
    "\n",
    "# Load Dataset\n",
    "data = SegExamples()\n",
    "data[0].keys()\n",
    "print(data[1]['type'])\n",
    "# print(examples.seg_examples_df)\n",
    "# print(data.seg_examples_df.keys())\n",
    "# plt.imshow(examples[1]['img'])\n",
    "# print(examples[1]['type'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\Lenovo\\\\PycharmProjects\\\\Skin_lesion_segmentation\\\\notebooks'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hair_removal(paths_list):\n",
    "    # red channel used. after mask creation, opening + dilation is applied to extend the mask.\n",
    "    count = 0\n",
    "    for i in paths_list:\n",
    "        p = \"data/\"+i\n",
    "        image = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "        # red_channel\n",
    "        red = image[:,:,2]\n",
    "\n",
    "        # Gaussian filter\n",
    "        gaussian= cv2.GaussianBlur(red,(3,3),cv2.BORDER_DEFAULT)\n",
    "\n",
    "        # Black hat filter\n",
    "        kernel = cv2.getStructuringElement(1,(20,20))\n",
    "        blackhat = cv2.morphologyEx(gaussian, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "        #Binary thresholding (MASK)\n",
    "        ret,mask = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n",
    "\n",
    "        # apply opening : erosion+dilation (remove the dots that are captured and then extend the hair parts)\n",
    "        kernel_opening = np.ones((1, 1), np.uint8)\n",
    "        opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_opening)\n",
    "        kernel_dilation = np.ones((5, 5), np.uint8)\n",
    "        dilated_mask = cv2.dilate(opening, kernel_dilation, iterations=1)\n",
    "\n",
    "        #Replace pixels of the mask\n",
    "        dst = cv2.inpaint(image,dilated_mask,6,cv2.INPAINT_TELEA)\n",
    "\n",
    "        count+=1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [48], line 24\u001B[0m\n\u001B[0;32m     22\u001B[0m dilated_mask \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mdilate(opening, kernel_dilation, iterations\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m#Replace pixels of the mask\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m dst \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39minpaint(img,dilated_mask,\u001B[38;5;241m6\u001B[39m,cv2\u001B[38;5;241m.\u001B[39mINPAINT_TELEA)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m## Border removal\u001B[39;00m\n\u001B[0;32m     27\u001B[0m image_cropped, y1, y2, x1, x2 \u001B[38;5;241m=\u001B[39m crop_img(dst)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Hir remova + K-means Segmentation\n",
    "paths = \"../data/\"+data.seg_examples_df.path\n",
    "count = 0\n",
    "for i in paths:\n",
    "    type = data[count]['type']\n",
    "    img = cv2.imread(i)\n",
    "\n",
    "    # Hair removal\n",
    "\n",
    "    red = img[:,:,2]\n",
    "    # Gaussian filter\n",
    "    gaussian= cv2.GaussianBlur(red,(3,3),cv2.BORDER_DEFAULT)\n",
    "    # Black hat filter\n",
    "    kernel = cv2.getStructuringElement(1,(20,20))\n",
    "    blackhat = cv2.morphologyEx(gaussian, cv2.MORPH_BLACKHAT, kernel)\n",
    "    #Binary thresholding (MASK)\n",
    "    ret,mask = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n",
    "    # apply opening : erosion+dilation (remove the dots that are captured and then extend the hair parts)\n",
    "    kernel_opening = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_opening)\n",
    "    kernel_dilation = np.ones((5, 5), np.uint8)\n",
    "    dilated_mask = cv2.dilate(opening, kernel_dilation, iterations=1)\n",
    "    #Replace pixels of the mask\n",
    "    dst = cv2.inpaint(img,dilated_mask,6,cv2.INPAINT_TELEA)\n",
    "\n",
    "    ## Border removal\n",
    "    image_cropped, y1, y2, x1, x2 = crop_img(dst)\n",
    "\n",
    "    # kmeans\n",
    "    image = cv2.cvtColor(image_cropped, cv2.COLOR_BGR2GRAY)\n",
    "    pixel_values = image.reshape(-1)\n",
    "    pixel_values = np.float32(pixel_values)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    k = 2\n",
    "    _, labels, (centers) = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    centers = np.uint8(centers)\n",
    "    labels = labels.flatten()\n",
    "    segmented_image = centers[labels.flatten()]\n",
    "    # reshape back to the original image dimension\n",
    "    segmented_image = segmented_image.reshape(image.shape)\n",
    "    ret1,seg_bin = cv2.threshold(segmented_image,127,255,cv2.THRESH_BINARY_INV)\n",
    "    # Save the image\n",
    "    count=count+1\n",
    "    cv2.imwrite(f'../examples/kmeans2/{type}_{count}.png', seg_bin)\n",
    "\n",
    "    # show the image\n",
    "    # plt.imshow(segmented_image, cmap=\"gray\")\n",
    "    # plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Base k meeans code\n",
    "paths = \"../data/\"+data.seg_examples_df.path\n",
    "count = 0\n",
    "for i in paths:\n",
    "    type = data[count]['type']\n",
    "    img = cv2.imread(i)\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pixel_values = image.reshape(-1,3)\n",
    "    pixel_values = np.float32(pixel_values)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    k = 2\n",
    "    _, labels, (centers) = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    centers = np.uint8(centers)\n",
    "    labels = labels.flatten()\n",
    "    segmented_image = centers[labels.flatten()]\n",
    "    # reshape back to the original image dimension\n",
    "    segmented_image = segmented_image.reshape(image.shape)\n",
    "    # Save the image\n",
    "    count=count+1\n",
    "    cv2.imwrite(f'../examples/kmeans/{type}_{count}.png', segmented_image)\n",
    "\n",
    "    # show the image\n",
    "    plt.imshow(segmented_image, cmap=\"gray\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TASKS\n",
    "# from the segmented image:\n",
    "# the color channel r,g,b = color histogram\n",
    "# mean, mode, std, skewness, energy, entropy, kurtosis\n",
    "# min and max values for each channel.\n",
    "# get the hsv space color info and calculate the same mean, ... for it too.\n",
    "# glcm - contrast, correlation, enegry, homogenity\n",
    "\n",
    "# extract local and global segmented image features and then compare them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[0, 0, 0],\n        [1, 1, 1],\n        [0, 0, 0],\n        ...,\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]],\n\n       [[1, 1, 1],\n        [0, 0, 0],\n        [1, 1, 1],\n        ...,\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]],\n\n       [[1, 1, 1],\n        [0, 0, 0],\n        [1, 1, 1],\n        ...,\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]],\n\n       ...,\n\n       [[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        ...,\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]],\n\n       [[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        ...,\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]],\n\n       [[0, 0, 0],\n        [1, 1, 1],\n        [1, 1, 1],\n        ...,\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]]], dtype=uint8)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Color histogram statistics\n",
    " data[1]['img']"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
